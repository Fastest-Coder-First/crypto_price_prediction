{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import tweepy as tw\n",
    "import threading\n",
    "import time\n",
    "import queue\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Twitter API. Specify the colummns we want to scrape.\n",
    "def get_df():\n",
    "    \"\"\" \n",
    "    Returns a dataframe with the columns we want to scrape.\n",
    "    \"\"\"\n",
    "    return pd.DataFrame(\n",
    "        columns=[\n",
    "            \"tweet_id\",\n",
    "            \"retweet_count\",\n",
    "            \"text\",\n",
    "            \"mined_at\",\n",
    "            \"created_at\",\n",
    "            \"hashtags\",\n",
    "            \"followers_count\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Twitter API ####\n",
    "class TweetMiner(object):\n",
    "    result_minit = 20\n",
    "    ret = []\n",
    "    api = False\n",
    "\n",
    "    # Use twitter_keys from config file\n",
    "    twitter_keys = {\n",
    "        \"consumer_key\": config.consumer_key,\n",
    "        \"consumer_secret\": config.consumer_secret,\n",
    "        \"access_token_key\": config.access_token_key,\n",
    "        \"access_token_secret\": config.access_token_secret,\n",
    "    }\n",
    "\n",
    "    def __init__(self, keys_dict=twitter_keys, api=api):\n",
    "        \"\"\" \n",
    "        Initialize the miner.\n",
    "        \"\"\"\n",
    "        self.api = api\n",
    "        auth = tw.OAuthHandler(keys_dict[\"consumer_key\"], keys_dict[\"consumer_secret\"])\n",
    "        auth.set_access_token(keys_dict[\"access_token_key\"], keys_dict[\"access_token_secret\"])\n",
    "        self.api = tw.API(auth, wait_on_rate_limit=True)\n",
    "        self.twitter_keys = keys_dict\n",
    "        self.path = Path(f'{os.getcwd()}')\n",
    "\n",
    "    def mine_tweets(self, query=\"BTC\"):\n",
    "        \"\"\"\n",
    "        Mine tweets from the query.\n",
    "        \"\"\"\n",
    "        last_tweet_id = False\n",
    "        page_num = 1\n",
    "\n",
    "        # Save in 'ret' the columns we are interested in scraping.\n",
    "        ret = get_df()\n",
    "\n",
    "        # Alter 'crypto_query' if you want to mine from specific dates\n",
    "        crypto_query = f\"#{query}\" #since:2022-03-03 until:2022-03-05\"\n",
    "        print(\"========\", query, crypto_query)\n",
    "\n",
    "        document_count = 0\n",
    "        for page in tw.Cursor(\n",
    "            self.api.search_tweets, \n",
    "            q=crypto_query, \n",
    "            lang=\"en\", \n",
    "            tweet_mode=\"extended\", \n",
    "            count=200\n",
    "        ).pages():\n",
    "            print(\"........... new page\", page_num)\n",
    "            page_num += 1\n",
    "\n",
    "            for tweet in page:\n",
    "                data = {\n",
    "                    \"tweet_id\": tweet.id,\n",
    "                    \"retweet_count\": tweet.retweet_count,\n",
    "                    \"text\": tweet.full_text,\n",
    "                    \"mined_at\": datetime.datetime.now(),\n",
    "                    \"created_at\": tweet.created_at,\n",
    "                    \"hashtags\": tweet.entities.get(\"hashtags\"),\n",
    "                    \"followers_count\": tweet.user.followers_count,\n",
    "                }\n",
    "                try:\n",
    "                    data[\"retweet_text\"] = tweet.retweeted_status.full_text\n",
    "                except:\n",
    "                    data[\"retweet_text\"] = \"None\"\n",
    "\n",
    "                last_tweet_id = tweet.id\n",
    "                ret = ret.append(data, ignore_index=True)\n",
    "\n",
    "            \n",
    "            if page_num % 180 == 0:\n",
    "                date_label = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "                file_name = f\"{date_label}-{query}-{document_count}.csv\"\n",
    "                print(\"Saving to file:\", file_name, \" after page number \", page_num)\n",
    "                ret.to_csv(file_name, index=False)\n",
    "                document_count += 1\n",
    "                print(\"Resetting df\")\n",
    "                ret = get_df()\n",
    "        date_label = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        ret.to_csv(f\"{self.Path}\\{date_label}-{query}-{document_count}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miner = TweetMiner()\n",
    "\n",
    "# Choose one handler at a time.\n",
    "handle_list = [\n",
    "    # \"DOGE\",\n",
    "    \"BTC\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "should_publish = threading.Event()\n",
    "update_queue = queue.Queue()\n",
    "\n",
    "\n",
    "def start_publisher():\n",
    "    \"\"\" \n",
    "    Start the publisher thread. (This is the thread that will be listening for updates)\n",
    "    \"\"\"\n",
    "    global handle_list\n",
    "\n",
    "    starttime = time.time()\n",
    "    print(\"Start polling\", starttime)\n",
    "    poll_iteration = 1\n",
    "\n",
    "    for i in range(10):\n",
    "        for name in handle_list[:1]:\n",
    "            print(i, poll_iteration, \"\\rpublishing update \", end=\"\")\n",
    "            update_queue.put((poll_iteration, name))\n",
    "            poll_iteration += 1\n",
    "            time.sleep(900)\n",
    "            print(\"\\rawaiting for publishing update\", end=\"\")\n",
    "            should_publish.wait()\n",
    "            update_queue.join()\n",
    "\n",
    "def start_update_listener():\n",
    "    \"\"\"\n",
    "    Start the update listener thread. (This is the thread that will be listening for updates)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        poll_iteration, name = update_queue.get()\n",
    "\n",
    "        print(\" --- \", name)\n",
    "        try:\n",
    "\n",
    "            miner.mine_tweets(query=name)\n",
    "            update_queue.task_done()\n",
    "\n",
    "        except Exception as e:  # work on python 3.x\n",
    "            print(\"Failed to upload to ftp: \" + str(e))\n",
    "\n",
    "# Start the threads\n",
    "listener_thread = threading.Thread(target=start_update_listener, daemon=True)\n",
    "publisher_thread = threading.Thread(target=start_publisher, daemon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the threads. \n",
    "publisher_thread.start()\n",
    "listener_thread.start()\n",
    "\n",
    "# Start publishing\n",
    "should_publish.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the threads. \n",
    "should_publish.clear()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "93263193325cd6f76a9e21d176003adfa7a63d8f308e38218ffc45e6019c4146"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
